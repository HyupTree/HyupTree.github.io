---
layout: til
title: "ì§€ë„í•™ìŠµ vs ë¹„ì§€ë„í•™ìŠµ - ë¨¸ì‹ ëŸ¬ë‹ì˜ ë‘ ê°€ì§€ ì ‘ê·¼ë²•"
date: 2024-09-14
category: machine-learning
tags: [supervised-learning, unsupervised-learning, machine-learning, classification, clustering]
---

## ğŸ¯ ë¨¸ì‹ ëŸ¬ë‹ì˜ ë‘ ê°€ì§€ í•™ìŠµ ë°©ë²•

ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì€ í¬ê²Œ **ì§€ë„ í•™ìŠµ(Supervised Learning)**ê³¼ **ë¹„ì§€ë„ í•™ìŠµ(Unsupervised Learning)**ìœ¼ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì€ í›ˆë ¨í•˜ê¸° ìœ„í•œ ë°ì´í„°ì™€ ì •ë‹µì´ í•„ìš”í•˜ì§€ë§Œ, ë¹„ì§€ë„ í•™ìŠµì€ ì •ë‹µ ì—†ì´ë„ ë°ì´í„°ì˜ íŒ¨í„´ì„ ì°¾ì•„ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ“š ì§€ë„ í•™ìŠµ (Supervised Learning)

### ì •ì˜
ì§€ë„ í•™ìŠµì€ **ì…ë ¥ ë°ì´í„°ì™€ ì •ë‹µ(ë ˆì´ë¸”)ì´ í•¨ê»˜ ì œê³µ**ë˜ëŠ” í•™ìŠµ ë°©ë²•ì…ë‹ˆë‹¤. ë§ˆì¹˜ ì„ ìƒë‹˜ì´ ì •ë‹µì„ ì•Œë ¤ì£¼ë©° ê°€ë¥´ì¹˜ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.

### íŠ¹ì§•
- **í›ˆë ¨ ë°ì´í„°**: ì…ë ¥ê°’(X)ê³¼ ì •ë‹µ(y)ì´ ìŒìœ¼ë¡œ êµ¬ì„±
- **ëª©í‘œ**: ìƒˆë¡œìš´ ì…ë ¥ì— ëŒ€í•´ ì •í™•í•œ ì¶œë ¥ì„ ì˜ˆì¸¡
- **í‰ê°€**: ì‹¤ì œ ì •ë‹µê³¼ ì˜ˆì¸¡ê°’ì„ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ ì¸¡ì •

### ì£¼ìš” ìœ í˜•

#### 1. ë¶„ë¥˜(Classification) ğŸ·ï¸
- **ëª©ì **: ë°ì´í„°ë¥¼ ë¯¸ë¦¬ ì •ì˜ëœ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
- **ì¶œë ¥**: ì´ì‚°ì ì¸ í´ë˜ìŠ¤ ë ˆì´ë¸”
- **ì˜ˆì‹œ**: 
  - ì´ë©”ì¼ ìŠ¤íŒ¸ ë¶„ë¥˜ (ìŠ¤íŒ¸/ì •ìƒ)
  - ì´ë¯¸ì§€ ë¶„ë¥˜ (ê³ ì–‘ì´/ê°œ/ìƒˆ)
  - ì§ˆë³‘ ì§„ë‹¨ (ì–‘ì„±/ìŒì„±)

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split

# ì•„ì´ë¦¬ìŠ¤ ë¶„ë¥˜ ì˜ˆì‹œ
iris = load_iris()
X, y = iris.data, iris.target

# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)  # í›ˆë ¨ ë°ì´í„°ì™€ ì •ë‹µìœ¼ë¡œ í•™ìŠµ

# ì˜ˆì¸¡ ë° ê²°ê³¼
predictions = clf.predict(X_test)
accuracy = clf.score(X_test, y_test)

print("ì˜ˆì¸¡ ê²°ê³¼:", predictions[:10])
print("ì‹¤ì œ ì •ë‹µ:", y_test[:10])
print(f"ì •í™•ë„: {accuracy:.3f}")
```

**ì¶œë ¥ ê²°ê³¼:**
```
ì˜ˆì¸¡ ê²°ê³¼: [1 0 2 1 1 0 1 2 1 1]
ì‹¤ì œ ì •ë‹µ: [1 0 2 1 1 0 1 2 1 1]
ì •í™•ë„: 1.000
```

#### 2. íšŒê·€(Regression) ğŸ“ˆ
- **ëª©ì **: ì—°ì†ì ì¸ ìˆ˜ì¹˜ê°’ ì˜ˆì¸¡
- **ì¶œë ¥**: ì‹¤ìˆ˜ê°’
- **ì˜ˆì‹œ**:
  - ì£¼íƒ ê°€ê²© ì˜ˆì¸¡
  - ì£¼ì‹ ê°€ê²© ì˜ˆì¸¡
  - ì˜¨ë„ ì˜ˆì¸¡

```python
from sklearn.linear_model import LinearRegression
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
import numpy as np

# ìº˜ë¦¬í¬ë‹ˆì•„ ì£¼íƒ ê°€ê²© ì˜ˆì¸¡ ì˜ˆì‹œ
housing = fetch_california_housing()
X, y = housing.data, housing.target

# í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

reg = LinearRegression()
reg.fit(X_train, y_train)  # ì§‘ íŠ¹ì„±ê³¼ ê°€ê²©ìœ¼ë¡œ í•™ìŠµ

# ì˜ˆì¸¡ ë° ê²°ê³¼
predictions = reg.predict(X_test[:5])
actual_prices = y_test[:5]

print("ì˜ˆì¸¡ ê°€ê²©:", np.round(predictions, 2))
print("ì‹¤ì œ ê°€ê²©:", np.round(actual_prices, 2))
print(f"RÂ² ì ìˆ˜: {reg.score(X_test, y_test):.3f}")
```

**ì¶œë ¥ ê²°ê³¼:**
```
ì˜ˆì¸¡ ê°€ê²©: [0.48 0.46 5.77 2.17 2.36]
ì‹¤ì œ ê°€ê²©: [0.48 0.46 5.00 2.18 2.78]
RÂ² ì ìˆ˜: 0.576
```

## ğŸ” ë¹„ì§€ë„ í•™ìŠµ (Unsupervised Learning)

### ì •ì˜
ë¹„ì§€ë„ í•™ìŠµì€ **ì •ë‹µ ì—†ì´ ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ íŒ¨í„´ì´ë‚˜ êµ¬ì¡°ë¥¼ ì°¾ì•„ë‚´ëŠ”** í•™ìŠµ ë°©ë²•ì…ë‹ˆë‹¤. ë°ì´í„° ìì²´ì—ì„œ ì˜ë¯¸ìˆëŠ” ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

### íŠ¹ì§•
- **í›ˆë ¨ ë°ì´í„°**: ì…ë ¥ê°’(X)ë§Œ ì œê³µ, ì •ë‹µ ì—†ìŒ
- **ëª©í‘œ**: ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ êµ¬ì¡°ë‚˜ íŒ¨í„´ ë°œê²¬
- **í‰ê°€**: ëª…í™•í•œ ì •ë‹µì´ ì—†ì–´ í‰ê°€ê°€ ì–´ë ¤ì›€

### ì£¼ìš” ìœ í˜•

#### 1. êµ°ì§‘í™”(Clustering) ğŸ¯
- **ëª©ì **: ìœ ì‚¬í•œ ë°ì´í„°ë¼ë¦¬ ê·¸ë£¹ìœ¼ë¡œ ë¬¶ê¸°
- **íŠ¹ì§•**: ê·¸ë£¹ì˜ ê°œìˆ˜ë‚˜ ê¸°ì¤€ì„ ë¯¸ë¦¬ ì •í•˜ì§€ ì•ŠìŒ
- **ì˜ˆì‹œ**:
  - ê³ ê° ì„¸ë¶„í™”
  - ìœ ì „ì ë¶„ì„
  - ì´ë¯¸ì§€ ë¶„í• 

```python
from sklearn.cluster import KMeans
from sklearn.datasets import make_blobs
import numpy as np

# ê³ ê° ì„¸ë¶„í™” ì˜ˆì‹œ (ê°€ìƒ ë°ì´í„°)
# ë‚˜ì´, ì†Œë“, êµ¬ë§¤íšŸìˆ˜ ë°ì´í„° ìƒì„±
customer_data, _ = make_blobs(n_samples=100, centers=3, n_features=2, 
                             random_state=42, cluster_std=1.5)

kmeans = KMeans(n_clusters=3, random_state=42)
customer_groups = kmeans.fit_predict(customer_data)

# ê° ê·¸ë£¹ì˜ ì¤‘ì‹¬ì 
centers = kmeans.cluster_centers_

print("ê³ ê° ê·¸ë£¹ ë¶„ë¥˜ ê²°ê³¼:", customer_groups[:10])
print("ê·¸ë£¹ë³„ ê³ ê° ìˆ˜:")
unique, counts = np.unique(customer_groups, return_counts=True)
for group, count in zip(unique, counts):
    print(f"  ê·¸ë£¹ {group}: {count}ëª…")
print("ê·¸ë£¹ ì¤‘ì‹¬ì :")
for i, center in enumerate(centers):
    print(f"  ê·¸ë£¹ {i}: [{center[0]:.2f}, {center[1]:.2f}]")
```

**ì¶œë ¥ ê²°ê³¼:**
```
ê³ ê° ê·¸ë£¹ ë¶„ë¥˜ ê²°ê³¼: [1 0 1 2 0 1 1 0 2 2]
ê·¸ë£¹ë³„ ê³ ê° ìˆ˜:
  ê·¸ë£¹ 0: 34ëª…
  ê·¸ë£¹ 1: 32ëª…
  ê·¸ë£¹ 2: 34ëª…
ê·¸ë£¹ ì¤‘ì‹¬ì :
  ê·¸ë£¹ 0: [-8.79, -8.52]
  ê·¸ë£¹ 1: [-1.38, 4.37]
  ê·¸ë£¹ 2: [3.71, -4.15]
```

#### 2. ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction) ğŸ“Š
- **ëª©ì **: ê³ ì°¨ì› ë°ì´í„°ë¥¼ ì €ì°¨ì›ìœ¼ë¡œ ë³€í™˜í•˜ë©´ì„œ ì¤‘ìš”í•œ ì •ë³´ ë³´ì¡´
- **ì¥ì **: ì‹œê°í™”, ë…¸ì´ì¦ˆ ì œê±°, ê³„ì‚° íš¨ìœ¨ì„± í–¥ìƒ
- **ì˜ˆì‹œ**:
  - ì£¼ì„±ë¶„ ë¶„ì„(PCA)
  - t-SNE
  - ë°ì´í„° ì‹œê°í™”

```python
from sklearn.decomposition import PCA
from sklearn.datasets import load_digits
import numpy as np

# ì†ê¸€ì”¨ ìˆ«ì ë°ì´í„° ì°¨ì› ì¶•ì†Œ ì˜ˆì‹œ
digits = load_digits()
X = digits.data  # 64ì°¨ì› ë°ì´í„° (8x8 í”½ì…€)

print("ì›ë³¸ ë°ì´í„° í˜•íƒœ:", X.shape)

# 2ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ
pca = PCA(n_components=2)
reduced_data = pca.fit_transform(X)

print("ì¶•ì†Œëœ ë°ì´í„° í˜•íƒœ:", reduced_data.shape)
print("ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨:", np.round(pca.explained_variance_ratio_, 3))
print("ì´ ì„¤ëª…ëœ ë¶„ì‚°:", np.round(pca.explained_variance_ratio_.sum(), 3))

# ì²« 5ê°œ ìƒ˜í”Œì˜ ì¶•ì†Œëœ ë°ì´í„°
print("ì¶•ì†Œëœ ë°ì´í„° (ì²« 5ê°œ):")
for i in range(5):
    print(f"  ìƒ˜í”Œ {i}: [{reduced_data[i][0]:.2f}, {reduced_data[i][1]:.2f}]")
```

**ì¶œë ¥ ê²°ê³¼:**
```
ì›ë³¸ ë°ì´í„° í˜•íƒœ: (1797, 64)
ì¶•ì†Œëœ ë°ì´í„° í˜•íƒœ: (1797, 2)
ì„¤ëª…ëœ ë¶„ì‚° ë¹„ìœ¨: [0.149 0.134]
ì´ ì„¤ëª…ëœ ë¶„ì‚°: 0.283
ì¶•ì†Œëœ ë°ì´í„° (ì²« 5ê°œ):
  ìƒ˜í”Œ 0: [-1.26, 21.27]
  ìƒ˜í”Œ 1: [7.95, 20.76]
  ìƒ˜í”Œ 2: [6.99, 9.95]
  ìƒ˜í”Œ 3: [16.94, 4.04]
  ìƒ˜í”Œ 4: [-4.87, 8.41]
```

#### 3. ì—°ê´€ ê·œì¹™ í•™ìŠµ(Association Rule Learning) ğŸ›’
- **ëª©ì **: ë°ì´í„° ê°„ì˜ ì—°ê´€ì„±ì´ë‚˜ ê·œì¹™ ë°œê²¬
- **ì˜ˆì‹œ**:
  - ì¥ë°”êµ¬ë‹ˆ ë¶„ì„ ("ë§¥ì£¼ë¥¼ ì‚¬ëŠ” ì‚¬ëŒì€ ê¸°ì €ê·€ë„ ì‚°ë‹¤")
  - ì¶”ì²œ ì‹œìŠ¤í…œ
  - ì›¹ ì‚¬ìš© íŒ¨í„´ ë¶„ì„

## ğŸ”„ ì§€ë„í•™ìŠµ vs ë¹„ì§€ë„í•™ìŠµ ë¹„êµ

<div class="comparison-table-wrapper">
  <table class="terminal-comparison-table">
    <thead>
      <tr>
        <th class="table-header-category">êµ¬ë¶„</th>
        <th class="table-header-supervised">ğŸ“ ì§€ë„í•™ìŠµ (Supervised Learning)</th>
        <th class="table-header-unsupervised">ğŸ” ë¹„ì§€ë„í•™ìŠµ (Unsupervised Learning)</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td class="table-category">ëª©í‘œ</td>
        <td class="table-supervised">ì •í™•í•œ ì˜ˆì¸¡/ë¶„ë¥˜ ìˆ˜í–‰</td>
        <td class="table-unsupervised">ìˆ¨ê²¨ì§„ íŒ¨í„´/êµ¬ì¡° ë°œê²¬</td>
      </tr>
      <tr>
        <td class="table-category">ë°ì´í„°</td>
        <td class="table-supervised">ì…ë ¥ ë°ì´í„° + ì •ë‹µ ë ˆì´ë¸”</td>
        <td class="table-unsupervised">ì…ë ¥ ë°ì´í„°ë§Œ (ë ˆì´ë¸” ì—†ìŒ)</td>
      </tr>
      <tr>
        <td class="table-category">í•™ìŠµ ë°©ì‹</td>
        <td class="table-supervised">ì •ë‹µì„ ë³´ê³  í•™ìŠµ</td>
        <td class="table-unsupervised">ë°ì´í„° ìì²´ì—ì„œ íŒ¨í„´ í•™ìŠµ</td>
      </tr>
      <tr>
        <td class="table-category">í‰ê°€ ë°©ë²•</td>
        <td class="table-supervised">ì •ë‹µê³¼ ì˜ˆì¸¡ê°’ ë¹„êµ<br/><span class="table-detail">(ì •í™•ë„, F1-score ë“±)</span></td>
        <td class="table-unsupervised">ë‚´ì¬ì  í‰ê°€<br/><span class="table-detail">(ì‹¤ë£¨ì—£ ì ìˆ˜, ì—˜ë³´ìš° ë°©ë²• ë“±)</span></td>
      </tr>
      <tr>
        <td class="table-category">ì£¼ìš” ê¸°ë²•</td>
        <td class="table-supervised">â€¢ ë¶„ë¥˜ (Classification)<br/>â€¢ íšŒê·€ (Regression)</td>
        <td class="table-unsupervised">â€¢ êµ°ì§‘í™” (Clustering)<br/>â€¢ ì°¨ì› ì¶•ì†Œ (Dimensionality Reduction)<br/>â€¢ ì—°ê´€ ê·œì¹™ (Association Rules)</td>
      </tr>
      <tr>
        <td class="table-category">ì•Œê³ ë¦¬ì¦˜ ì˜ˆì‹œ</td>
        <td class="table-supervised"><span class="algorithm-tag">Random Forest</span><br/><span class="algorithm-tag">SVM</span><br/><span class="algorithm-tag">Linear Regression</span><br/><span class="algorithm-tag">KNN</span></td>
        <td class="table-unsupervised"><span class="algorithm-tag">K-Means</span><br/><span class="algorithm-tag">PCA</span><br/><span class="algorithm-tag">DBSCAN</span><br/><span class="algorithm-tag">Apriori</span></td>
      </tr>
      <tr>
        <td class="table-category">ì‹¤ë¬´ í™œìš©</td>
        <td class="table-supervised">â€¢ ì´ë©”ì¼ ìŠ¤íŒ¸ ë¶„ë¥˜<br/>â€¢ ì£¼íƒ ê°€ê²© ì˜ˆì¸¡<br/>â€¢ ì§ˆë³‘ ì§„ë‹¨<br/>â€¢ ì´ë¯¸ì§€ ì¸ì‹</td>
        <td class="table-unsupervised">â€¢ ê³ ê° ì„¸ë¶„í™”<br/>â€¢ ì¶”ì²œ ì‹œìŠ¤í…œ<br/>â€¢ ì´ìƒ íƒì§€<br/>â€¢ ë°ì´í„° ì‹œê°í™”</td>
      </tr>
      <tr>
        <td class="table-category">â±í•™ìŠµ ì‹œê°„</td>
        <td class="table-supervised"><span class="status-fast">ìƒëŒ€ì ìœ¼ë¡œ ë¹ ë¦„</span></td>
        <td class="table-unsupervised"><span class="status-slow">ìƒëŒ€ì ìœ¼ë¡œ ëŠë¦¼</span></td>
      </tr>
      <tr>
        <td class="table-category">ë°ì´í„° ìš”êµ¬ì‚¬í•­</td>
        <td class="table-supervised">ê³ í’ˆì§ˆ ë ˆì´ë¸” ë°ì´í„° í•„ìˆ˜</td>
        <td class="table-unsupervised">ë ˆì´ë¸” ë¶ˆí•„ìš”, ëŒ€ìš©ëŸ‰ ë°ì´í„° ì„ í˜¸</td>
      </tr>
      <tr>
        <td class="table-category">ê²°ê³¼ í•´ì„</td>
        <td class="table-supervised"><span class="status-easy">ëª…í™•í•˜ê³  ì§ê´€ì </span></td>
        <td class="table-unsupervised"><span class="status-hard">ë„ë©”ì¸ ì§€ì‹ í•„ìš”, í•´ì„ ì–´ë ¤ì›€</span></td>
      </tr>
      <tr>
        <td class="table-category">í‰ê°€ ë‚œì´ë„</td>
        <td class="table-supervised"><span class="status-easy">ì‰¬ì›€ (ëª…í™•í•œ ê¸°ì¤€)</span></td>
        <td class="table-unsupervised"><span class="status-hard">ì–´ë ¤ì›€ (ì£¼ê´€ì  íŒë‹¨)</span></td>
      </tr>
    </tbody>
  </table>
</div>

## ğŸ› ï¸ ì‹¤ì œ ë°ì´í„°ì…‹ ì˜ˆì‹œ

### ì§€ë„í•™ìŠµ ë°ì´í„°ì…‹
```python
import numpy as np

# ì…ë ¥ ë°ì´í„°ì™€ ì •ë‹µì´ í•¨ê»˜ ì œê³µ
input_arr = np.array([[5.1, 3.5, 1.4, 0.2],  # ê½ƒì ê¸¸ì´, ë„ˆë¹„ ë“±
                      [4.9, 3.0, 1.4, 0.2],
                      [6.2, 3.4, 5.4, 2.3]])

labels = np.array([0, 0, 2])  # ì•„ì´ë¦¬ìŠ¤ ì¢…ë¥˜ (setosa, versicolor, virginica)

print("ì…ë ¥ ë°ì´í„° í˜•íƒœ:", input_arr.shape)
print("ì…ë ¥ ë°ì´í„°:")
print(input_arr)
print("ì •ë‹µ ë ˆì´ë¸”:", labels)
print("ë ˆì´ë¸” ì¢…ë¥˜:", np.unique(labels))
```

**ì¶œë ¥ ê²°ê³¼:**
```
ì…ë ¥ ë°ì´í„° í˜•íƒœ: (3, 4)
ì…ë ¥ ë°ì´í„°:
[[5.1 3.5 1.4 0.2]
 [4.9 3.  1.4 0.2]
 [6.2 3.4 5.4 2.3]]
ì •ë‹µ ë ˆì´ë¸”: [0 0 2]
ë ˆì´ë¸” ì¢…ë¥˜: [0 2]
```

### ë¹„ì§€ë„í•™ìŠµ ë°ì´í„°ì…‹
```python
import numpy as np

# ì…ë ¥ ë°ì´í„°ë§Œ ì œê³µ, ì •ë‹µ ì—†ìŒ
customer_data = np.array([[25, 50000, 3],    # ë‚˜ì´, ì†Œë“, êµ¬ë§¤íšŸìˆ˜
                          [35, 75000, 5],
                          [45, 60000, 2],
                          [28, 45000, 4],
                          [52, 80000, 1]])

print("ê³ ê° ë°ì´í„° í˜•íƒœ:", customer_data.shape)
print("ê³ ê° ë°ì´í„°:")
print(customer_data)
print("ë°ì´í„° í†µê³„:")
print("  í‰ê·  ë‚˜ì´:", np.mean(customer_data[:, 0]))
print("  í‰ê·  ì†Œë“:", np.mean(customer_data[:, 1]))
print("  í‰ê·  êµ¬ë§¤íšŸìˆ˜:", np.mean(customer_data[:, 2]))

# ì •ë‹µ ì—†ì´ íŒ¨í„´ì„ ì°¾ì•„ ê³ ê°ì„ ê·¸ë£¹í™”
# ì•Œê³ ë¦¬ì¦˜ì´ ìŠ¤ìŠ¤ë¡œ ìœ ì‚¬í•œ ê³ ê°ë“¤ì„ ë¬¶ì–´ì¤Œ
```

**ì¶œë ¥ ê²°ê³¼:**
```
ê³ ê° ë°ì´í„° í˜•íƒœ: (5, 3)
ê³ ê° ë°ì´í„°:
[[   25 50000     3]
 [   35 75000     5]
 [   45 60000     2]
 [   28 45000     4]
 [   52 80000     1]]
ë°ì´í„° í†µê³„:
  í‰ê·  ë‚˜ì´: 37.0
  í‰ê·  ì†Œë“: 62000.0
  í‰ê·  êµ¬ë§¤íšŸìˆ˜: 3.0
```

## ğŸ¯ ì–¸ì œ ì–´ë–¤ ë°©ë²•ì„ ì‚¬ìš©í• ê¹Œ?

### ì§€ë„í•™ìŠµì„ ì„ íƒí•˜ëŠ” ê²½ìš°
- **ëª…í™•í•œ ëª©í‘œ**ê°€ ìˆì„ ë•Œ (ë¶„ë¥˜, ì˜ˆì¸¡)
- **ì¶©ë¶„í•œ ë ˆì´ë¸” ë°ì´í„°**ê°€ ìˆì„ ë•Œ
- **ì„±ëŠ¥ ì¸¡ì •**ì´ ì¤‘ìš”í•  ë•Œ

### ë¹„ì§€ë„í•™ìŠµì„ ì„ íƒí•˜ëŠ” ê²½ìš°
- **ë°ì´í„° íƒìƒ‰**ì´ ëª©ì ì¼ ë•Œ
- **ë ˆì´ë¸” ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¶€ì¡±**í•  ë•Œ
- **ìˆ¨ê²¨ì§„ íŒ¨í„´ ë°œê²¬**ì´ ëª©í‘œì¼ ë•Œ

## ğŸ’¡ ì‹¤ë¬´ íŒ

1. **ë°ì´í„° ì¤€ë¹„**: ì§€ë„í•™ìŠµì€ ê³ í’ˆì§ˆì˜ ë ˆì´ë¸” ë°ì´í„°ê°€ í•µì‹¬
2. **ë¬¸ì œ ì •ì˜**: ëª©í‘œê°€ ì˜ˆì¸¡ì¸ì§€ íƒìƒ‰ì¸ì§€ ëª…í™•íˆ í•˜ê¸°
3. **í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼**: ë¹„ì§€ë„í•™ìŠµìœ¼ë¡œ ë°ì´í„° íƒìƒ‰ í›„ ì§€ë„í•™ìŠµ ì ìš©
4. **í‰ê°€ ë°©ë²•**: ê° í•™ìŠµ ë°©ë²•ì— ì í•©í•œ í‰ê°€ ì§€í‘œ ì„ íƒ

## ğŸ“š ë§ˆë¬´ë¦¬

ì§€ë„í•™ìŠµê³¼ ë¹„ì§€ë„í•™ìŠµì€ ê°ê° ë‹¤ë¥¸ ìƒí™©ì—ì„œ ìœ ìš©í•œ ë„êµ¬ì…ë‹ˆë‹¤. **ì •ë‹µì´ ìˆëŠ” ë¬¸ì œ**ëŠ” ì§€ë„í•™ìŠµìœ¼ë¡œ, **ë°ì´í„°ì˜ ìˆ¨ê²¨ì§„ êµ¬ì¡°ë¥¼ ì°¾ëŠ” ë¬¸ì œ**ëŠ” ë¹„ì§€ë„í•™ìŠµìœ¼ë¡œ ì ‘ê·¼í•˜ëŠ” ê²ƒì´ íš¨ê³¼ì ì…ë‹ˆë‹¤. ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œëŠ” ë‘ ë°©ë²•ì„ ì¡°í•©í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤. 